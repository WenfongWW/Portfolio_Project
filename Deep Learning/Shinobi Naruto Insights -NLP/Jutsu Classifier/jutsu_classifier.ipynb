{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import torch\n",
    "import numpy as np\n",
    "from bs4 import BeautifulSoup\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch import nn\n",
    "from sklearn.metrics import classification_report\n",
    "from transformers import AutoTokenizer\n",
    "from transformers import AutoModelForSequenceClassification\n",
    "from transformers import DataCollatorWithPadding\n",
    "from datasets import load_dataset\n",
    "from transformers import TrainingArguments, Trainer\n",
    "import evaluate\n",
    "from datasets import Dataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data prepration "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"distilbert-base-uncased\"\n",
    "\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>jutsu_name</th>\n",
       "      <th>jutsu_type</th>\n",
       "      <th>jutsu_description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10 Hit Combo</td>\n",
       "      <td>Taijutsu</td>\n",
       "      <td>Lars punches the opponent before striking them...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Avalanche Dance</td>\n",
       "      <td>Taijutsu, Shurikenjutsu</td>\n",
       "      <td>Haku delivers a string of kicks, punches, and ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Attack of the Twin Demons</td>\n",
       "      <td>Kekkei Genkai, Ninjutsu</td>\n",
       "      <td>This technique allows Ukon to inhabit his brot...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Bando's Chakra Armour</td>\n",
       "      <td>Ninjutsu</td>\n",
       "      <td>Bando activates his chakra to surround him in ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Ball of Light Technique</td>\n",
       "      <td>Ninjutsu</td>\n",
       "      <td>The user gathers a ball of concentrated light ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  jutsu_name               jutsu_type  \\\n",
       "0               10 Hit Combo                 Taijutsu   \n",
       "1            Avalanche Dance  Taijutsu, Shurikenjutsu   \n",
       "2  Attack of the Twin Demons  Kekkei Genkai, Ninjutsu   \n",
       "3      Bando's Chakra Armour                 Ninjutsu   \n",
       "4    Ball of Light Technique                 Ninjutsu   \n",
       "\n",
       "                                   jutsu_description  \n",
       "0  Lars punches the opponent before striking them...  \n",
       "1  Haku delivers a string of kicks, punches, and ...  \n",
       "2  This technique allows Ukon to inhabit his brot...  \n",
       "3  Bando activates his chakra to surround him in ...  \n",
       "4  The user gathers a ball of concentrated light ...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_path = \"C:/Users/Wen/OneDrive/Documents/GitHub/Portfolio_Project/Deep Learning/Shinobi Naruto Insights -NLP/Web Scraping/jutsu.jsonl\"\n",
    "\n",
    "df = pd.read_json(data_path, lines=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3_types_of_jutsu\n",
       "Ninjutsu    2009\n",
       "Taijutsu     628\n",
       "Genjutsu      79\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def jutsu_types(jutsu):\n",
    "    if \"Taijutsu\" in jutsu:\n",
    "        return \"Taijutsu\"\n",
    "    if \"Ninjutsu\" in jutsu:\n",
    "        return \"Ninjutsu\"\n",
    "    if \"Genjutsu\" in jutsu:\n",
    "        return \"Genjutsu\"\n",
    "    \n",
    "    return None\n",
    "\n",
    "df[\"3_types_of_jutsu\"] = df[\"jutsu_type\"].apply(jutsu_types)\n",
    "df[\"3_types_of_jutsu\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['jutsu_name', 'jutsu_type', 'jutsu_description', '3_types_of_jutsu'], dtype='object')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                   text     jutsu\n",
      "0     10 Hit Combo. Lars punches the opponent before...  Taijutsu\n",
      "1     Avalanche Dance. Haku delivers a string of kic...  Taijutsu\n",
      "2     Attack of the Twin Demons. This technique allo...  Ninjutsu\n",
      "3     Bando's Chakra Armour. Bando activates his cha...  Ninjutsu\n",
      "4     Ball of Light Technique. The user gathers a ba...  Ninjutsu\n",
      "...                                                 ...       ...\n",
      "2867  Absolute: Fang Passing Fang. Kiba and Akamaru ...  Taijutsu\n",
      "2868  16 Hit Combo. A very effective move, Ino uses ...  Taijutsu\n",
      "2869  1000 Metre Punch. The user focuses a large amo...  Taijutsu\n",
      "2870  100% Single Punch. Tsunade gathers large amoun...  Taijutsu\n",
      "2871  100 Metre Punch. A shorter version of the 1000...  Taijutsu\n",
      "\n",
      "[2716 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "df['text'] = df['jutsu_name']+ '. '+df['jutsu_description']\n",
    "df['jutsu'] = df['3_types_of_jutsu']\n",
    "df= df[['text','jutsu']].dropna()\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Clean Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def put_line_breaks(self, text):\n",
    "    text = text.replace('\\n', ' ')\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Cleaner():\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def remove_html_tags(self, text):\n",
    "        \"\"\"Remove HTML tags using BeautifulSoup.\"\"\"\n",
    "        cleantext = BeautifulSoup(text, \"lxml\").text\n",
    "        return cleantext\n",
    "    \n",
    "    def clean(self, text):\n",
    "        \"\"\"Clean text by removing HTML tags and standardizing white space.\"\"\"\n",
    "        text = self.remove_html_tags(text)\n",
    "        text = ' '.join(text.split())\n",
    "        return text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Wen\\AppData\\Local\\Temp\\ipykernel_33360\\1622832901.py:7: MarkupResemblesLocatorWarning: The input looks more like a filename than markup. You may want to open this file and pass the filehandle into Beautiful Soup.\n",
      "  cleantext = BeautifulSoup(text, \"lxml\").text\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       10 Hit Combo. Lars punches the opponent before...\n",
      "1       Avalanche Dance. Haku delivers a string of kic...\n",
      "2       Attack of the Twin Demons. This technique allo...\n",
      "3       Bando's Chakra Armour. Bando activates his cha...\n",
      "4       Ball of Light Technique. The user gathers a ba...\n",
      "                              ...                        \n",
      "2867    Absolute: Fang Passing Fang. Kiba and Akamaru ...\n",
      "2868    16 Hit Combo. A very effective move, Ino uses ...\n",
      "2869    1000 Metre Punch. The user focuses a large amo...\n",
      "2870    100% Single Punch. Tsunade gathers large amoun...\n",
      "2871    100 Metre Punch. A shorter version of the 1000...\n",
      "Name: text_cleaned, Length: 2716, dtype: object\n"
     ]
    }
   ],
   "source": [
    "cleaned_data = Cleaner()\n",
    "df['text_cleaned'] = df[\"text\"].apply(cleaned_data.clean)\n",
    "print(df['text_cleaned'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Label Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>jutsu</th>\n",
       "      <th>text_cleaned</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10 Hit Combo. Lars punches the opponent before...</td>\n",
       "      <td>Taijutsu</td>\n",
       "      <td>10 Hit Combo. Lars punches the opponent before...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Avalanche Dance. Haku delivers a string of kic...</td>\n",
       "      <td>Taijutsu</td>\n",
       "      <td>Avalanche Dance. Haku delivers a string of kic...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Attack of the Twin Demons. This technique allo...</td>\n",
       "      <td>Ninjutsu</td>\n",
       "      <td>Attack of the Twin Demons. This technique allo...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Bando's Chakra Armour. Bando activates his cha...</td>\n",
       "      <td>Ninjutsu</td>\n",
       "      <td>Bando's Chakra Armour. Bando activates his cha...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Ball of Light Technique. The user gathers a ba...</td>\n",
       "      <td>Ninjutsu</td>\n",
       "      <td>Ball of Light Technique. The user gathers a ba...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text     jutsu  \\\n",
       "0  10 Hit Combo. Lars punches the opponent before...  Taijutsu   \n",
       "1  Avalanche Dance. Haku delivers a string of kic...  Taijutsu   \n",
       "2  Attack of the Twin Demons. This technique allo...  Ninjutsu   \n",
       "3  Bando's Chakra Armour. Bando activates his cha...  Ninjutsu   \n",
       "4  Ball of Light Technique. The user gathers a ba...  Ninjutsu   \n",
       "\n",
       "                                        text_cleaned  label  \n",
       "0  10 Hit Combo. Lars punches the opponent before...      2  \n",
       "1  Avalanche Dance. Haku delivers a string of kic...      2  \n",
       "2  Attack of the Twin Demons. This technique allo...      1  \n",
       "3  Bando's Chakra Armour. Bando activates his cha...      1  \n",
       "4  Ball of Light Technique. The user gathers a ba...      1  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder = LabelEncoder()\n",
    "encoder.fit(df[\"jutsu\"].tolist())\n",
    "df['label'] = encoder.transform(df[\"jutsu\"].tolist())\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Class Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11.459915611814345, 0.45063879210220675, 1.4416135881104033]\n"
     ]
    }
   ],
   "source": [
    "class_weights = compute_class_weight('balanced',\n",
    "                     classes=sorted(df['label'].unique().tolist()),\n",
    "                     y=df['label'].tolist()).tolist()\n",
    "\n",
    "print(class_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4 Train Testing Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train,df_test = train_test_split(df,test_size=0.2,stratify=df['label'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.5 Convert to HuggingFace Datast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = Dataset.from_pandas(df_train)\n",
    "test_data = Dataset.from_pandas(df_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.6 Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Wen\\anaconda3\\Lib\\site-packages\\huggingface_hub\\file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3fa587e4b33a459b90eeaf068c44d14f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2172 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e123c09a3bf24aadb36184d4f547cfff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/544 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased\")\n",
    "\n",
    "def preprocess_function(examples):\n",
    "    return tokenizer(examples[\"text_cleaned\"], truncation=True)\n",
    "\n",
    "tokenized_train = train_data.map(preprocess_function, batched=True)\n",
    "tokenized_test = test_data.map(preprocess_function, batched=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Initialize Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForSequenceClassification.from_pretrained(\"distilbert-base-uncased\", num_labels=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Train Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f12b6dc09bc44ef9f503af270fcc2d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading builder script:   0%|          | 0.00/4.20k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
    "metric = evaluate.load(\"accuracy\")\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    return metric.compute(predictions=predictions, references=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomTrainer(Trainer):\n",
    "    def compute_loss(self, model, inputs, return_outputs=False):\n",
    "        labels = inputs.get(\"labels\")\n",
    "        outputs = model(**inputs)\n",
    "        logits = outputs.get(\"logits\")\n",
    "        loss_fct = nn.CrossEntropyLoss(weight=torch.tensor(class_weights).to(device=device))\n",
    "        loss = loss_fct(logits.view(-1, self.model.config.num_labels), labels.view(-1))\n",
    "        return (loss, outputs) if return_outputs else loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Wen\\anaconda3\\Lib\\site-packages\\accelerate\\accelerator.py:436: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches', 'even_batches', 'use_seedable_sampler']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e7469372b59f47a88408cab76f19cfc4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1360 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.1086, 'grad_norm': 5.426770210266113, 'learning_rate': 0.00016, 'epoch': 1.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cb6464dd9eec47dea081da815136bcbc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/68 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.0859078168869019, 'eval_accuracy': 0.6433823529411765, 'eval_runtime': 85.8532, 'eval_samples_per_second': 6.336, 'eval_steps_per_second': 0.792, 'epoch': 1.0}\n",
      "{'loss': 1.0699, 'grad_norm': 2.3903634548187256, 'learning_rate': 0.00012, 'epoch': 2.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d3139a81387b409e9c09c95e9201a12e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/68 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.0219625234603882, 'eval_accuracy': 0.5091911764705882, 'eval_runtime': 68.82, 'eval_samples_per_second': 7.905, 'eval_steps_per_second': 0.988, 'epoch': 2.0}\n",
      "{'loss': 1.0212, 'grad_norm': 9.947807312011719, 'learning_rate': 8e-05, 'epoch': 3.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a50fe089cf340128e64bea531ccbf95",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/68 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.2136396169662476, 'eval_accuracy': 0.23161764705882354, 'eval_runtime': 72.7804, 'eval_samples_per_second': 7.475, 'eval_steps_per_second': 0.934, 'epoch': 3.0}\n",
      "{'loss': 1.1019, 'grad_norm': 12.017338752746582, 'learning_rate': 4e-05, 'epoch': 4.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1cb7a79fea7d444cb4932fc33bdb9ad5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/68 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.0760619640350342, 'eval_accuracy': 0.7591911764705882, 'eval_runtime': 78.1538, 'eval_samples_per_second': 6.961, 'eval_steps_per_second': 0.87, 'epoch': 4.0}\n",
      "{'loss': 0.9576, 'grad_norm': 7.100297451019287, 'learning_rate': 0.0, 'epoch': 5.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "61091c66e6264a9a904e95a7313ddd1f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/68 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.982421875, 'eval_accuracy': 0.7591911764705882, 'eval_runtime': 102.9114, 'eval_samples_per_second': 5.286, 'eval_steps_per_second': 0.661, 'epoch': 5.0}\n",
      "{'train_runtime': 5717.3386, 'train_samples_per_second': 1.899, 'train_steps_per_second': 0.238, 'train_loss': 1.0518485798555262, 'epoch': 5.0}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=1360, training_loss=1.0518485798555262, metrics={'train_runtime': 5717.3386, 'train_samples_per_second': 1.899, 'train_steps_per_second': 0.238, 'train_loss': 1.0518485798555262, 'epoch': 5.0})"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    learning_rate=2e-4,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    num_train_epochs=5,\n",
    "    weight_decay=0.01,\n",
    "    evaluation_strategy = \"epoch\",\n",
    "    logging_strategy=\"epoch\"\n",
    ")\n",
    "\n",
    "trainer = CustomTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_train,\n",
    "    eval_dataset=tokenized_test,\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.save_model('jutsu_model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Evaluate Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "58b82297bbea44809503d94999908935",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/272 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        63\n",
      "           1       0.87      0.84      0.85      1607\n",
      "           2       0.56      0.69      0.62       502\n",
      "\n",
      "    accuracy                           0.78      2172\n",
      "   macro avg       0.48      0.51      0.49      2172\n",
      "weighted avg       0.77      0.78      0.77      2172\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Wen\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\Wen\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\Wen\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "preds = trainer.predict(tokenized_train)\n",
    "preds = np.argmax(preds[:3][0],axis=1)\n",
    "actual = df_train['label'].tolist()\n",
    "print(classification_report(actual,preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc55e7a743b74de8a2d188ab45af3134",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/68 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        16\n",
      "           1       0.85      0.84      0.84       402\n",
      "           2       0.52      0.61      0.56       126\n",
      "\n",
      "    accuracy                           0.76       544\n",
      "   macro avg       0.46      0.48      0.47       544\n",
      "weighted avg       0.75      0.76      0.75       544\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Wen\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\Wen\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\Wen\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "preds = trainer.predict(tokenized_test)\n",
    "preds = np.argmax(preds[:3][0],axis=1)\n",
    "actual = df_test['label'].tolist()\n",
    "print(classification_report(actual,preds))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
